// GRADIENT DESCENT
def train_linreg_gd(X, y, lr, epochs):
	num_datapoints, num_features = X.shape
	weights = np.zeros((num_features, 1))
	bias = 0
	
	for i in range(epochs):
		y_predict = np.dot(X, weights) + bias
		cost = (1/data_points)*np.sum((y_predict-y)**2)

		# calculate gradients
		grad_weights = (1/num_datapoints)*np.sum((y_predict-y))
		grad_bias = (1/num_datapoints)*np.sum((y_predict-y))
		weights -= lr * grad_weights
		bias -= lr * grad_bias
	
	return weights, bias


def train_linreg(X, y):
	weights = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)),X.T), y)
	return weights